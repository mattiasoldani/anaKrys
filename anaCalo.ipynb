{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "super-valuation",
   "metadata": {},
   "source": [
    "# **anaCalo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "protected-remark",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# set %matplotlib inline (%matplotlib widget, %matplotlib qt) for static (interactive on-page, interactive in separate window) plots\n",
    "# in order to use the on-page interactive mode, make sure the environment is set up properly\n",
    "# comment this out before exporting the notebook to a Python script -- via jupyter nbconvert --to script anaKrys.ipynb\n",
    "%matplotlib widget\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import importlib\n",
    "import succolib as sl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# internal modules (in .modules), shared with anaKrys\n",
    "from modules import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-pathology",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-assist",
   "metadata": {},
   "source": [
    "## **data input settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "shaped-alloy",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# test mode controller: if True (False), the software runs with test (custom, selected via settingsFileMods) settings and data\n",
    "boolTest = False\n",
    "\n",
    "# label of the settings fileset to load -- useless if boolTest=True\n",
    "settingsFileMods = \"y21StormCernH2\"\n",
    "\n",
    "# file type, either \"ASCII\" or \"ROOT\"\n",
    "filetype = \"ROOT\"\n",
    "\n",
    "# file name structure\n",
    "# list of XXXXXX (run nrs.) to be set below\n",
    "# will cycle on all available YYYYYY (file nrs.)\n",
    "filename = \"/eos/user/m/msoldani/succo/phd_nocloud/data_local/21_cern_h2_storm/root/runXXXXXX.root\"\n",
    "\n",
    "# calorimeter name (like in dictionary z, e.g. caloFwd)\n",
    "# by default, this sticks to the convention of having the first letter lowercase (uppercase) when standalone (with a prefix, e.g. in digiPHRawCaloFwd)\n",
    "name_cal = \"caloFwd\"\n",
    "\n",
    "# names of Si layers for tracking, ((hor0, hor1), (ver0, ver1))\n",
    "ind_track = ((\"4\", \"6\"), (\"5\", \"7\"))\n",
    "\n",
    "# names of other Si layers in the calo. path (not for tracking, just for single-hit event selection), (x0, x1, ...)\n",
    "# can be left empty\n",
    "ind_layers_1hit = (\"0\", \"1\", \"2\", \"3\")\n",
    "\n",
    "# list of runs for equalisation, w/ respective beam energies, {ch: {energy: XXXXXX}}\n",
    "# these keys will also be used as list calo. channels to involve (ind_calo)\n",
    "runs_eq = {\n",
    "    # GENNI:\n",
    "    \"CaloFwd0\" : {150: \"500322\"},\n",
    "    \"CaloFwd1\" : {150: \"500314\"},\n",
    "    \"CaloFwd2\" : {150: \"500316\"},\n",
    "    \"CaloFwd3\" : {150: \"500321\"},\n",
    "    \"CaloFwd4\" : {150: \"500313\"},\n",
    "    \"CaloFwd5\" : {150: \"500317\"},\n",
    "    \"CaloFwd6\" : {150: \"500320\"},\n",
    "    \"CaloFwd7\" : {150: \"500319\"},\n",
    "    \"CaloFwd8\" : {150: \"500318\"},\n",
    "#     \"CaloFwd3\" : {150: \"500321\", 130: \"500321\"},\n",
    "#     \"CaloFwd4\" : {150: \"500313\", 130: \"500313\"},\n",
    "#     \"CaloFwd5\" : {150: \"500317\", 130: \"500317\"},\n",
    "}\n",
    "\n",
    "# list of energies for calibration\n",
    "#ls_calib_energies = (18.071282, 36.083447, 54.023162, 71.889726, 89.720555, 107.531272)\n",
    "ls_calib_energies = (20, 40, 60, 80, 100, 120)\n",
    "\n",
    "# list of runs for calibration, 1 per energy, in the same order as in ls_calib_energies, {calorimeter: (run0, run1, ...)}\n",
    "ls_calib_runs = {\n",
    "    # GENNI:\n",
    "    \"caloFwd\": (\"500305\", \"500304\", \"500307\", \"500303\", \"500306\", \"500301\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-classroom",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-fifth",
   "metadata": {},
   "source": [
    "## **load external settings & data input**\n",
    "#### to dataframe ```df```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "instrumental-projection",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "runs_calib = dict(zip(ls_calib_energies, ls_calib_runs[name_cal]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "controversial-sponsorship",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for files with label y21StormCernH2 in ./settings/\n",
      "execution control booleans:\n",
      "data reload controller: True\n",
      "test mode controller: False\n"
     ]
    }
   ],
   "source": [
    "# import settings, according to boolTest and settingsFileMods\n",
    "# function in .modules --> set ./settings/__init__.py for settings fileset selection\n",
    "mod_runList_name, mod_settings_name = settingsSelect(boolTest, whichInput = fileType if boolTest else settingsFileMods)\n",
    "globals().update(importlib.import_module(mod_runList_name).__dict__)\n",
    "globals().update(importlib.import_module(mod_settings_name).__dict__)\n",
    "\n",
    "# print only (functions in .modules)\n",
    "boolControlPrint(True, boolTest, filetype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abandoned-mediterranean",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# base names for Si data variables, i.e. positions and nrs. of hit\n",
    "var_x = \"xRaw\"\n",
    "var_nhit = \"nHit\"\n",
    "\n",
    "# base names for calo. data variables, i.e. PHs and times\n",
    "var_ph = \"digiPHRaw\"\n",
    "var_time = \"digiTime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "offshore-austin",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening ROOT files... --> data into DataFrame df\n",
      "progressbars won't be visualized...\n",
      "(1/15) 500301 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(2/15) 500303 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(3/15) 500304 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(4/15) 500305 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(5/15) 500306 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(6/15) 500307 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(7/15) 500313 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(8/15) 500314 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(9/15) 500316 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(10/15) 500317 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(11/15) 500318 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(12/15) 500319 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(13/15) 500320 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(14/15) 500321 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "(15/15) 500322 -- descaling fraction: 1.000000000000\n",
      "remapping some ROOT tree variables (from tree map given)\n",
      "no variables to mirror\n",
      "iRun also added to df\n",
      "--\n",
      "typeRun added to df\n"
     ]
    }
   ],
   "source": [
    "ind_calo = list(runs_eq.keys())  # list of calo. channel names\n",
    "\n",
    "# list of variables to be extracted from raw data\n",
    "ls_vars = [\"iRun\"]\n",
    "ls_vars += [\"typeRun\"]\n",
    "ls_vars += [var_x+s for i in range(2) for s in ind_track[i]]\n",
    "ls_vars += [var_nhit+s for i in range(2) for s in ind_track[i]]\n",
    "ls_vars += [var_nhit+s for s in ind_layers_1hit]\n",
    "ls_vars += [var_ph+s for s in ind_calo]\n",
    "ls_vars += [var_time+s for s in ind_calo]\n",
    "\n",
    "# list of all runs to be opened\n",
    "runs_all = list()\n",
    "for ch in runs_eq:\n",
    "    for energy in runs_eq[ch]:\n",
    "        runs_all.append(runs_eq[ch][energy])\n",
    "runs_all += list(runs_calib.values())\n",
    "\n",
    "# open data files and set dataframe up\n",
    "df, dt = loadGeneral(filetype, filename, {s: nRun0[s] for s in runs_all}, {}, mirrorMap, globals(), False)\n",
    "# df = df[list(set(ls_vars))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-exhibit",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-generator",
   "metadata": {},
   "source": [
    "## **tracking**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-vulnerability",
   "metadata": {},
   "source": [
    "#### **settings here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "actual-video",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# initial settings\n",
    "ch_tracking = (\"eq\", 150, \"CaloFwd4\")  # data to be used for tracking, (\"eq\"/\"calib\", energy, ch)\n",
    "# note: if \"calib\" is selected, ch is not used to select a run but it is used to select a channel to cut on\n",
    "ch_tracking_thresh = (150, 250)  # threshold on PH to highlight calo. channel, for plots with single, selected channel\n",
    "xcalo_range = ((-1, 6), (-1, 6))  # range of beam spot single-channel 2d histograms, ((left, right), (lower, upper))\n",
    "\n",
    "# resulting cuts, to be set here for plotting purposes\n",
    "ang_cut_eq = (250, 250)  # cuts on input angles (wt. distibution weighted average) in urad, for equalisation, (hor, ver)\n",
    "fid_eq = ((1.85, 2.95), (1.95, 3.05))  # fiducial box @ calorimeter plane, for equalisation, ((hor0, hor1), (ver0, ver1))\n",
    "ls_calib_angles = (  # cuts on input angles (wrt. distibution weighted average) in urad, for calibration, per energy (same order as in ls_calib_energies), (hor, ver)\n",
    "    (1000, 1000),  # nominal energy: 20\n",
    "    (600, 600), # nominal energy: 40\n",
    "    (500, 500), # nominal energy: 60\n",
    "    (400, 400), # nominal energy: 80\n",
    "    (300, 300), # nominal energy: 100\n",
    "    (300, 300), # nominal energy: 120\n",
    ")\n",
    "ls_calib_fid = {  # fiducial box @ calorimeter plane, for calibration, per energy (same order as in ls_calib_energies), {calorimeter: ((hor0, hor1), (ver0, ver1))}\n",
    "    \"caloFwd\": (  # GENNI\n",
    "        ((-0.3, 5.2), (-0.5, 5.0)),  # nominal energy: 20\n",
    "        ((-0.3, 5.2), (-0.5, 5.0)),  # nominal energy: 40\n",
    "        ((0.7, 4.2), (0.5, 4.0)),  # nominal energy: 60\n",
    "        ((0.7, 4.2), (0.5, 4.0)),  # nominal energy: 80\n",
    "        ((0.7, 4.2), (0.5, 4.0)),  # nominal energy: 100\n",
    "        ((0.7, 4.2), (0.5, 4.0)),  # nominal energy: 120\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "based-crest",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ang_cut_calib = dict(zip(ls_calib_energies, ls_calib_angles))\n",
    "fid_calib = dict(zip(ls_calib_energies, ls_calib_fid[name_cal]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "respiratory-insight",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create necessary booleans\n",
    "b_run_tr = df.iRun==runs_eq[ch_tracking[2]][ch_tracking[1]] if ch_tracking[0]==\"eq\" else df.iRun==runs_calib[ch_tracking[1]]\n",
    "b_1hit = (df[var_nhit+ind_track[0][0]]==1) & (df[var_nhit+ind_track[0][1]]==1) & (df[var_nhit+ind_track[1][0]]==1) & (df[var_nhit+ind_track[1][1]]==1)\n",
    "for layer in ind_layers_1hit:\n",
    "    b_1hit = b_1hit & (df[var_nhit+layer]==1)\n",
    "b_xgood = (abs(df[var_x+ind_track[0][0]])<20) & (abs(df[var_x+ind_track[0][1]])<20) & (abs(df[var_x+ind_track[1][0]])<20) & (abs(df[var_x+ind_track[1][1]])<20)\n",
    "\n",
    "# create tracking-related variables\n",
    "for side in range(2):\n",
    "    dz = (z[runs_all[0]][ind_track[side][1]]-z[runs_all[0]][ind_track[side][0]], z[runs_all[0]][name_cal]-z[runs_all[0]][ind_track[side][1]])  # caeful, using positions for first run opened\n",
    "    df[\"thIn%d\" % side] = sl.zAngle(df[var_x+ind_track[side][1]], dz[0], df[var_x+ind_track[side][0]], 0) * 1e6  # converted into urad\n",
    "    df[\"xCal%d\" % side] = sl.zProj(df[var_x+ind_track[side][1]], dz[0], df[var_x+ind_track[side][0]], 0, dz[0]+dz[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "decimal-capability",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c1dfb7e686446cac76696ee4489060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontal centre = -856.128410 urad\n",
      "vertical centre = -1741.142595 urad\n"
     ]
    }
   ],
   "source": [
    "plt.close(\"input_angle\")\n",
    "fig = plt.figure(\"input_angle\", figsize=(6, 5))\n",
    "\n",
    "plt.subplot(211)\n",
    "hist = plt.hist(df[b_run_tr&b_1hit&b_xgood].thIn0, bins=100);\n",
    "ang_ave_x = np.average([hist[1][i]+0.5*(hist[1][i+1]-hist[1][i]) for i in range(len(hist[1])-1)], weights=hist[0])\n",
    "plt.axvline(ang_ave_x, c=\"C1\")\n",
    "plt.axvline(ang_ave_x-ang_cut_eq[0], c=\"magenta\", ls=\":\", label=\"fid. cuts for equalisation\")\n",
    "plt.axvline(ang_ave_x+ang_cut_eq[0], c=\"magenta\", ls=\":\")\n",
    "plt.axvline(ang_ave_x-ang_cut_calib[np.max(list(runs_calib.keys()))][0], c=\"lime\", ls=\":\", label=\"fid. cuts for calibration (%d GeV)\" % np.max(list(runs_calib.keys())))\n",
    "plt.axvline(ang_ave_x+ang_cut_calib[np.max(list(runs_calib.keys()))][0], c=\"lime\", ls=\":\")\n",
    "plt.axvline(ang_ave_x-ang_cut_calib[np.min(list(runs_calib.keys()))][0], c=\"red\", ls=\":\", label=\"fid. cuts for calibration (%d GeV)\" % np.min(list(runs_calib.keys())))\n",
    "plt.axvline(ang_ave_x+ang_cut_calib[np.min(list(runs_calib.keys()))][0], c=\"red\", ls=\":\")\n",
    "plt.title(\"horizontal\", loc=\"left\")\n",
    "print(\"horizontal centre = %f urad\" % ang_ave_x)\n",
    "\n",
    "plt.subplot(212)\n",
    "hist = plt.hist(df[b_run_tr&b_1hit&b_xgood].thIn1, bins=100);\n",
    "ang_ave_y = np.average([hist[1][i]+0.5*(hist[1][i+1]-hist[1][i]) for i in range(len(hist[1])-1)], weights=hist[0])\n",
    "plt.axvline(ang_ave_y, c=\"C1\")\n",
    "plt.axvline(ang_ave_y-ang_cut_eq[1], c=\"magenta\", ls=\":\")\n",
    "plt.axvline(ang_ave_y+ang_cut_eq[1], c=\"magenta\", ls=\":\")\n",
    "plt.axvline(ang_ave_y-ang_cut_calib[np.max(list(runs_calib.keys()))][1], c=\"lime\", ls=\":\")\n",
    "plt.axvline(ang_ave_y+ang_cut_calib[np.max(list(runs_calib.keys()))][1], c=\"lime\", ls=\":\")\n",
    "plt.axvline(ang_ave_y-ang_cut_calib[np.min(list(runs_calib.keys()))][1], c=\"red\", ls=\":\")\n",
    "plt.axvline(ang_ave_y+ang_cut_calib[np.min(list(runs_calib.keys()))][1], c=\"red\", ls=\":\")\n",
    "plt.title(\"vertical\", loc=\"left\")\n",
    "print(\"vertical centre = %f urad\" % ang_ave_y)\n",
    "\n",
    "fig.legend(framealpha=1, loc=\"upper right\")\n",
    "plt.ylabel('entries', loc=\"bottom\")\n",
    "plt.xlabel(r\"input angle [$\\mu$rad]\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "little-portrait",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# creating booleans for cuts on angles here\n",
    "b_angle_eq = (abs(df.thIn0-ang_ave_x) < ang_cut_eq[0]) & (abs(df.thIn1-ang_ave_y) < ang_cut_eq[1])\n",
    "b_angle_calib = {}\n",
    "for energy in runs_calib:\n",
    "    b_angle_calib.update({energy: (abs(df.thIn0-ang_ave_x) < ang_cut_calib[energy][0]) & (abs(df.thIn1-ang_ave_y) < ang_cut_calib[energy][1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "electric-petite",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71108dcf037944499c82e3a02475e7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close(\"profile_at_calo\")\n",
    "fig, ax = plt.subplots(num = \"profile_at_calo\", figsize=(8, 7), nrows=2, ncols=2)\n",
    "\n",
    "b_ph_tr = (df[var_ph+ch_tracking[2]] > ch_tracking_thresh[0]) & (df[var_ph+ch_tracking[2]] < ch_tracking_thresh[1])\n",
    "\n",
    "ax[0, 0].hist2d(df[b_angle_eq&b_run_tr&b_1hit].xCal0, df[b_angle_eq&b_run_tr&b_1hit].xCal1, range=xcalo_range, bins=100);\n",
    "ax[0, 0].set_title(\"beam spot\")\n",
    "ax[0, 0].add_patch(patches.Rectangle(\n",
    "    (fid_eq[0][0], fid_eq[1][0]), fid_eq[0][1]-fid_eq[0][0], fid_eq[1][1]-fid_eq[1][0],\n",
    "    fill=False, edgecolor=\"magenta\", label=\"fid. cut for equalisation\"\n",
    "))\n",
    "ax[0, 0].add_patch(patches.Rectangle(\n",
    "    (fid_calib[np.max(list(runs_calib.keys()))][0][0], fid_calib[np.max(list(runs_calib.keys()))][1][0]), \n",
    "    fid_calib[np.max(list(runs_calib.keys()))][0][1] - fid_calib[np.max(list(runs_calib.keys()))][0][0], \n",
    "    fid_calib[np.max(list(runs_calib.keys()))][1][1] - fid_calib[np.max(list(runs_calib.keys()))][1][0], \n",
    "    fill=False, edgecolor=\"lime\", label=\"fid. cut for calibration (%d GeV)\" % np.max(list(runs_calib.keys()))\n",
    "))\n",
    "ax[0, 0].add_patch(patches.Rectangle(\n",
    "    (fid_calib[np.min(list(runs_calib.keys()))][0][0], fid_calib[np.min(list(runs_calib.keys()))][1][0]), \n",
    "    fid_calib[np.min(list(runs_calib.keys()))][0][1] - fid_calib[np.min(list(runs_calib.keys()))][0][0], \n",
    "    fid_calib[np.min(list(runs_calib.keys()))][1][1] - fid_calib[np.min(list(runs_calib.keys()))][1][0], \n",
    "    fill=False, edgecolor=\"red\", label=\"fid. cut for calibration (%d GeV)\" % np.min(list(runs_calib.keys()))\n",
    "))\n",
    "\n",
    "ax[0, 1].hist2d(df[b_angle_eq&b_run_tr&b_1hit&b_ph_tr].xCal0, df[b_angle_eq&b_run_tr&b_1hit&b_ph_tr].xCal1, range=xcalo_range, bins=100);\n",
    "ax[0, 1].set_title(\"beam spot when signal in ch. %s\" % ch_tracking[2])\n",
    "ax[0, 1].add_patch(patches.Rectangle(\n",
    "    (fid_eq[0][0], fid_eq[1][0]), fid_eq[0][1]-fid_eq[0][0], fid_eq[1][1]-fid_eq[1][0],\n",
    "    fill=False, edgecolor=\"magenta\", label=\"fid. cut for equalisation\"\n",
    "))\n",
    "ax[0, 1].add_patch(patches.Rectangle(\n",
    "    (fid_calib[np.max(list(runs_calib.keys()))][0][0], fid_calib[np.max(list(runs_calib.keys()))][1][0]), \n",
    "    fid_calib[np.max(list(runs_calib.keys()))][0][1] - fid_calib[np.max(list(runs_calib.keys()))][0][0], \n",
    "    fid_calib[np.max(list(runs_calib.keys()))][1][1] - fid_calib[np.max(list(runs_calib.keys()))][1][0], \n",
    "    fill=False, edgecolor=\"lime\", label=\"fid. cut for calibration (%d GeV)\" % np.max(list(runs_calib.keys()))\n",
    "))\n",
    "ax[0, 1].add_patch(patches.Rectangle(\n",
    "    (fid_calib[np.min(list(runs_calib.keys()))][0][0], fid_calib[np.min(list(runs_calib.keys()))][1][0]), \n",
    "    fid_calib[np.min(list(runs_calib.keys()))][0][1] - fid_calib[np.min(list(runs_calib.keys()))][0][0], \n",
    "    fid_calib[np.min(list(runs_calib.keys()))][1][1] - fid_calib[np.min(list(runs_calib.keys()))][1][0], \n",
    "    fill=False, edgecolor=\"red\", label=\"fid. cut for calibration (%d GeV)\" % np.min(list(runs_calib.keys()))\n",
    "))\n",
    "\n",
    "sl.hist2dRatio(\n",
    "    df[b_angle_eq&b_run_tr&b_1hit&b_ph_tr].xCal0, df[b_angle_eq&b_run_tr&b_1hit&b_ph_tr].xCal1,\n",
    "    df[b_angle_eq&b_run_tr&b_1hit].xCal0, df[b_angle_eq&b_run_tr&b_1hit].xCal1,\n",
    "    range=xcalo_range, bins=100, ax=ax[1, 0]\n",
    ");\n",
    "ax[1, 0].add_patch(patches.Rectangle((fid_eq[0][0], fid_eq[1][0]), fid_eq[0][1]-fid_eq[0][0], fid_eq[1][1]-fid_eq[1][0], fill=False, edgecolor=\"magenta\"))\n",
    "ax[1, 0].add_patch(patches.Rectangle(\n",
    "    (fid_calib[np.max(list(runs_calib.keys()))][0][0], fid_calib[np.max(list(runs_calib.keys()))][1][0]), \n",
    "    fid_calib[np.max(list(runs_calib.keys()))][0][1] - fid_calib[np.max(list(runs_calib.keys()))][0][0], \n",
    "    fid_calib[np.max(list(runs_calib.keys()))][1][1] - fid_calib[np.max(list(runs_calib.keys()))][1][0], \n",
    "    fill=False, edgecolor=\"lime\"\n",
    "))\n",
    "ax[1, 0].add_patch(patches.Rectangle(\n",
    "    (fid_calib[np.min(list(runs_calib.keys()))][0][0], fid_calib[np.min(list(runs_calib.keys()))][1][0]), \n",
    "    fid_calib[np.min(list(runs_calib.keys()))][0][1] - fid_calib[np.min(list(runs_calib.keys()))][0][0], \n",
    "    fid_calib[np.min(list(runs_calib.keys()))][1][1] - fid_calib[np.min(list(runs_calib.keys()))][1][0], \n",
    "    fill=False, edgecolor=\"red\"\n",
    "))\n",
    "ax[1, 0].set_title(\"ratio\")\n",
    "\n",
    "ax[1, 1].axis(\"off\")\n",
    "fig.legend(framealpha=1, loc=\"lower center\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-annex",
   "metadata": {},
   "source": [
    "### **full-detector beam profile (with relative shifts), dedicated settings here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "excessive-kentucky",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d569def81f2447d489a61e093aa8edf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b_plot = True  # plot this?\n",
    "ch_tracking_thresh_large = (50, 200)  # threshold on PH to highlight calo. channel, for plots with full calo.\n",
    "xcalo_range_large = ((-2, 7), (-2, 7))  # range of beam spot full-calo. 2d histograms, ((left, right), (lower, upper))\n",
    "xcalo_shift = {  # shifts (relative to centre) for each channel, {ch: [hor, ver]}\n",
    "    \"CaloFwd0\" : [2.5, -2.5],\n",
    "    \"CaloFwd1\" : [0.0, -2.5],\n",
    "    \"CaloFwd2\" : [-2.5, -2.5],\n",
    "    \"CaloFwd3\" : [2.5, 0.0],\n",
    "    \"CaloFwd4\" : [0.0, 0.0],\n",
    "    \"CaloFwd5\" : [-2.5, 0.0],\n",
    "    \"CaloFwd6\" : [2.5, 2.5],\n",
    "    \"CaloFwd7\" : [0.0, 2.5],\n",
    "    \"CaloFwd8\" : [-2.5, 2.5],\n",
    "}\n",
    "# # # # # # # # # #\n",
    "\n",
    "if b_plot:\n",
    "    plt.close(\"profile_at_calo_full\")\n",
    "    fig, ax = plt.subplots(num = \"profile_at_calo_full\", figsize=(5, 5))\n",
    "\n",
    "    for ich, ch in enumerate(ind_calo):\n",
    "        for ienergy, energy in enumerate(runs_eq[ch]):\n",
    "            b_run_tr_temp = df.iRun == runs_eq[ch][energy]\n",
    "            b_ph_tr_temp = (df[var_ph+ch] > ch_tracking_thresh_large[0]) & (df[var_ph+ch] < ch_tracking_thresh_large[1])\n",
    "            if (ich==0) & (ienergy==0):\n",
    "                hist, xedges, yedges = np.histogram2d(  # x & y swapped for imshow\n",
    "                    df[b_angle_eq&b_run_tr_temp&b_1hit&b_ph_tr_temp].xCal1 + xcalo_shift[ch][1], \n",
    "                    df[b_angle_eq&b_run_tr_temp&b_1hit&b_ph_tr_temp].xCal0 + xcalo_shift[ch][0], \n",
    "                    range=xcalo_range_large, bins=100\n",
    "                )\n",
    "            else:\n",
    "                hist_temp, _, _ = np.histogram2d(  # x & y swapped for imshow\n",
    "                    df[b_angle_eq&b_run_tr_temp&b_1hit&b_ph_tr_temp].xCal1 + xcalo_shift[ch][1], \n",
    "                    df[b_angle_eq&b_run_tr_temp&b_1hit&b_ph_tr_temp].xCal0 + xcalo_shift[ch][0], \n",
    "                    range=xcalo_range_large, bins=100\n",
    "                )\n",
    "                hist = hist + hist_temp\n",
    "    ax.imshow(hist, interpolation='nearest', origin='lower', extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])\n",
    "\n",
    "    for ich, ch in enumerate(ind_calo):\n",
    "        ax.text(\n",
    "            fid_eq[0][0] + xcalo_shift[ch][0]+0.5*(fid_eq[0][1]-fid_eq[0][0]),\n",
    "            fid_eq[1][0] + xcalo_shift[ch][1]+0.5*(fid_eq[1][1]-fid_eq[1][0]),\n",
    "            \"%s\" % ch, color=\"1\", weight=\"black\", fontsize=\"large\", ha=\"center\", va=\"center\"\n",
    "        )\n",
    "        ax.add_patch(patches.Rectangle((\n",
    "            fid_eq[0][0] + xcalo_shift[ch][0], fid_eq[1][0] + xcalo_shift[ch][1]),\n",
    "            fid_eq[0][1]-fid_eq[0][0], fid_eq[1][1]-fid_eq[1][0],\n",
    "            fill=False, edgecolor=\"magenta\", label=\"fid. cuts for equalisation\" if (ich==0) else None\n",
    "        ))\n",
    "    ax.add_patch(patches.Rectangle(\n",
    "        (fid_calib[np.max(list(runs_calib.keys()))][0][0], fid_calib[np.max(list(runs_calib.keys()))][1][0]), \n",
    "        fid_calib[np.max(list(runs_calib.keys()))][0][1] - fid_calib[np.max(list(runs_calib.keys()))][0][0], \n",
    "        fid_calib[np.max(list(runs_calib.keys()))][1][1] - fid_calib[np.max(list(runs_calib.keys()))][1][0], \n",
    "        fill=False, edgecolor=\"lime\", label=\"fid. cut for calibration (%d GeV)\" % np.max(list(runs_calib.keys()))\n",
    "    ))\n",
    "    ax.add_patch(patches.Rectangle(\n",
    "        (fid_calib[np.min(list(runs_calib.keys()))][0][0], fid_calib[np.min(list(runs_calib.keys()))][1][0]), \n",
    "        fid_calib[np.min(list(runs_calib.keys()))][0][1] - fid_calib[np.min(list(runs_calib.keys()))][0][0], \n",
    "        fid_calib[np.min(list(runs_calib.keys()))][1][1] - fid_calib[np.min(list(runs_calib.keys()))][1][0], \n",
    "        fill=False, edgecolor=\"red\", label=\"fid. cut for calibration (%d GeV)\" % np.min(list(runs_calib.keys()))\n",
    "    ))\n",
    "    fig.legend(framealpha=1, loc=\"upper right\")\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-darkness",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-county",
   "metadata": {},
   "source": [
    "## **timing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "economic-reset",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cuts on calo. channel time spectra, {ch: [min, max]}\n",
    "cut_time = digiTimeCut[runs_all[0]]  # caeful, using cuts for first run opened\n",
    "cut_time = {s: cut_time[s] for s in cut_time.keys() if (name_cal[0].upper() + name_cal[1:] in s)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "european-distinction",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a88c98033f24de98f4d09432837d5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close(\"time_spectra\")\n",
    "fig = plt.figure(\"time_spectra\", figsize=(8, 3))\n",
    "\n",
    "for ich, ch in enumerate(runs_eq):\n",
    "    energy = list(runs_eq[ch].keys())[0]\n",
    "    b_run_timing = df.iRun==runs_eq[ch][energy]\n",
    "    hist = np.histogram(df[b_run_timing][var_time+ch], bins=50, density=True)\n",
    "    y_max = np.max(hist[0])\n",
    "    plt.plot([hist[1][i]+0.5*(hist[1][i+1]-hist[1][i]) for i in range(len(hist[1])-1)], np.array(hist[0])+(0.2*ich*y_max), label=\"ch. %s\" % ch);\n",
    "    \n",
    "for icut, cut in enumerate(list(set(list(tuple(x) for x in cut_time.values())))):\n",
    "    if len(list(set(list(tuple(x) for x in cut_time.values()))))==1:\n",
    "        plt.axvline(cut[0], lw=1, ls=\"--\", color=str(0.2*icut+0.1), label=\"time cut\")\n",
    "        plt.axvline(cut[1], lw=1, ls=\"--\", color=str(0.2*icut+0.1))\n",
    "    else:\n",
    "        plt.axvline(cut[0], lw=1, ls=\"--\", color=str(0.2*icut+0.1), label=\"time cut %d\" % icut)\n",
    "        plt.axvline(cut[1], lw=1, ls=\"--\", color=str(0.2*icut+0.1))\n",
    "    \n",
    "plt.xlabel(\"time tick\")\n",
    "plt.ylabel(\"entries [a.u.]\")\n",
    "fig.legend(framealpha=1, loc=\"upper right\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-uncertainty",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-cable",
   "metadata": {},
   "source": [
    "## **equalisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-walter",
   "metadata": {},
   "source": [
    "### **general settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "enhanced-clarity",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# max. ADC value plots & nr. of ADC per bin (equalisation)\n",
    "adc_range_eq = 500\n",
    "d_adc_eq = 10\n",
    "\n",
    "# calo. ref. channel for equalisation\n",
    "ch_ref_eq = \"CaloFwd4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-houston",
   "metadata": {},
   "source": [
    "### **dataset** (```df_eq```) **creation & cleansing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "above-packet",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "b_runs_eq = False\n",
    "for ch in runs_eq:\n",
    "    for energy in runs_eq[ch]:\n",
    "        b_runs_eq = b_runs_eq | (df.iRun==runs_eq[ch][energy])\n",
    "b_fid_eq = (df.xCal0>fid_eq[0][0]) & (df.xCal0<fid_eq[0][1]) & (df.xCal0>fid_eq[1][0]) & (df.xCal0<fid_eq[1][1])\n",
    "\n",
    "df_eq = df[b_1hit&b_xgood&b_angle_eq&b_runs_eq&b_fid_eq]\n",
    "\n",
    "# also, creating bin array\n",
    "bins_eq = np.arange(0, adc_range_eq, d_adc_eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-import",
   "metadata": {},
   "source": [
    "### **raw spectra check, all channels for a specific run**\n",
    "**(subject to boolean, settings below)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "comparable-wisdom",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "b_plot = False  # plot this?\n",
    "energy_plot = 150  # choose energy\n",
    "ch_ref_plot = \"CaloFwd4\"  # choose run referred to a specific channel\n",
    "# # # # # # # # # #\n",
    "\n",
    "if b_plot:\n",
    "    plt.close(\"ph_calo_centre_check_eq\")\n",
    "    plt.figure(\"ph_calo_centre_check_eq\", figsize=(8, 3))\n",
    "\n",
    "    for ich, ch in enumerate(ind_calo):\n",
    "        b_run_temp = df_eq.iRun==runs_eq[ch_ref_plot][energy_plot]\n",
    "        b_time = (df_eq[var_time+ch]>cut_time[ch][0]) & (df_eq[var_time+ch]<cut_time[ch][1])\n",
    "        hist = np.histogram(df_eq[b_run_temp&b_time][var_ph+ch], bins=bins_eq, density=True)\n",
    "        y_max = max(hist[0])\n",
    "        plt.plot([hist[1][i]+0.5*(hist[1][i+1]-hist[1][i]) for i in range(len(hist[1])-1)], np.array(hist[0]), label=\"ch. %s\" % ch);\n",
    "        plt.xlabel(\"PH [ADC]\")\n",
    "        plt.ylabel(\"entries [a.u.]\")\n",
    "            \n",
    "    plt.legend(framealpha=1, loc=\"upper right\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-share",
   "metadata": {},
   "source": [
    "### **single-channel, single energy spectra**\n",
    "**(plots can be drawn upon request, settings below)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "compressed-louisville",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch. CaloFwd0 @ energy 150 GeV: PH MPV = 133.927705\n",
      "ch. CaloFwd1 @ energy 150 GeV: PH MPV = 64.092150\n",
      "ch. CaloFwd2 @ energy 150 GeV: PH MPV = 92.629571\n",
      "ch. CaloFwd3 @ energy 150 GeV: PH MPV = 87.379208\n",
      "ch. CaloFwd4 @ energy 150 GeV: PH MPV = 32.887400\n",
      "ch. CaloFwd5 @ energy 150 GeV: PH MPV = 42.713145\n",
      "ch. CaloFwd6 @ energy 150 GeV: PH MPV = 107.003095\n",
      "ch. CaloFwd7 @ energy 150 GeV: PH MPV = 191.923343\n",
      "ch. CaloFwd8 @ energy 150 GeV: PH MPV = 64.604964\n"
     ]
    }
   ],
   "source": [
    "b_plot = False  # draw the sample plot?\n",
    "ch_plot = \"CaloFwd4\"  # choose channel for the plot\n",
    "energy_plot = 150  # choose energy for the plot\n",
    "# # # # # # # # # #\n",
    "\n",
    "mpv_eq = {}\n",
    "\n",
    "for ch in runs_eq:\n",
    "    mpv_eq.update({ch: {}})\n",
    "    b_time = (df_eq[var_time+ch]>cut_time[ch][0]) & (df_eq[var_time+ch]<cut_time[ch][1])\n",
    "    \n",
    "    for energy in runs_eq[ch]:        \n",
    "        b_run_temp = df_eq.iRun==runs_eq[ch][energy]\n",
    "        hist = np.histogram(df_eq[b_run_temp&b_time][var_ph+ch], bins=bins_eq)\n",
    "        \n",
    "        ifwhm0 = np.argmax(hist[0]>=0.5*np.max(hist[0]))\n",
    "        fwhm0 = hist[1][ifwhm0]\n",
    "        ifwhm1 = ifwhm0 + np.argmax(hist[0][ifwhm0:]<=0.5*np.max(hist[0]))\n",
    "        fwhm1 = hist[1][ifwhm1]\n",
    "        par0 = (np.max(hist[0]), hist[1][np.argmax(hist[0]==np.max(hist[0]))], np.max((fwhm1-fwhm0, abs(hist[1][1]-hist[1][0]))))\n",
    "        imin = np.argmax(hist[0]>0.1*np.max(hist[0]))\n",
    "        x_fit = [hist[1][i]+0.5*(hist[1][i+1]-hist[1][i]) for i in range(len(hist[1])-1)][imin:]\n",
    "        y_fit = hist[0][imin:]\n",
    "        par, _ = curve_fit(sl.fLandau, x_fit, y_fit, p0=par0)\n",
    "        \n",
    "        if (b_plot & (ch==ch_plot) & (energy==energy_plot)):\n",
    "            plt.close(\"example_raw_spectrum\")\n",
    "            plt.figure(\"example_raw_spectrum\")\n",
    "            plt.plot([hist[1][i]+0.5*(hist[1][i+1]-hist[1][i]) for i in range(len(hist[1])-1)], hist[0]);\n",
    "            plt.plot(np.linspace(np.min(x_fit), adc_range_eq, 1000), sl.fLandau(np.linspace(np.min(x_fit), adc_range_eq, 1000), *par))\n",
    "            plt.xlabel(\"PH [ADC]\")\n",
    "            plt.ylabel(\"entries\")\n",
    "            plt.title(\"selected MIPs from ch. %s\" % ch_plot)\n",
    "            \n",
    "        mpv_eq[ch].update({energy: par[1]})\n",
    "        print(\"ch. %2s @ energy %3d GeV: PH MPV = %f\" % (ch, energy, mpv_eq[ch][energy]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-castle",
   "metadata": {},
   "source": [
    "### **equalisation parameters** &mdash; in ```eq_par```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "latter-flight",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equalisation factor for ch. CaloFwd0 = 0.245561\n",
      "equalisation factor for ch. CaloFwd1 = 0.513127\n",
      "equalisation factor for ch. CaloFwd2 = 0.355042\n",
      "equalisation factor for ch. CaloFwd3 = 0.376376\n",
      "equalisation factor for ch. CaloFwd4 = 1.000000\n",
      "equalisation factor for ch. CaloFwd5 = 0.769960\n",
      "equalisation factor for ch. CaloFwd6 = 0.307350\n",
      "equalisation factor for ch. CaloFwd7 = 0.171357\n",
      "equalisation factor for ch. CaloFwd8 = 0.509054\n"
     ]
    }
   ],
   "source": [
    "eq_par = {}\n",
    "\n",
    "for ch in runs_eq:\n",
    "    if len(runs_eq[ch].keys())==1:\n",
    "        eq_par.update({ch: mpv_eq[ch_ref_eq][list(runs_eq[ch_ref_eq].keys())[0]]/mpv_eq[ch][list(runs_eq[ch].keys())[0]]})\n",
    "        print(\"equalisation factor for ch. %2s = %f\" % (ch, eq_par[ch]))\n",
    "        \n",
    "#     else:  # CASE W/ MORE THAN 1 EQUALISATION POINT PER CHANNEL YET TO BE CONSIDERED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-syndrome",
   "metadata": {},
   "source": [
    "### **equalised spectra check, each channel from his run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "monthly-woman",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2fb15bc2c548d18ed19ad92456f8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close(\"ph_spectra_equalised\")\n",
    "fig = plt.figure(\"ph_spectra_equalised\", figsize=(8, 4))\n",
    "\n",
    "for ich, ch in enumerate(runs_eq):\n",
    "    if len(runs_eq[ch].keys())==1:\n",
    "        energy = list(runs_eq[ch].keys())[0]\n",
    "        b_run_temp = df_eq.iRun==runs_eq[ch][energy]\n",
    "        b_time = (df_eq[var_time+ch]>cut_time[ch][0]) & (df_eq[var_time+ch]<cut_time[ch][1])\n",
    "        hist = np.histogram(eq_par[ch]*df_eq[b_run_temp&b_time][var_ph+ch], bins=bins_eq, density=True)\n",
    "        y_max = max(hist[0])\n",
    "        plt.plot([hist[1][i]+0.5*(hist[1][i+1]-hist[1][i]) for i in range(len(hist[1])-1)], np.array(hist[0])+0.5*ich*y_max, label=\"ch. %s\" % ch);\n",
    "        plt.xlabel(\"PH equalised to ch %s [ADC]\" % ch_ref_eq)\n",
    "        plt.ylabel(\"entries [a.u.]\")\n",
    "        \n",
    "#     else:  # CASE W/ MORE THAN 1 EQUALISATION POINT PER CHANNEL YET TO BE CONSIDERED\n",
    "    \n",
    "plt.axvline(mpv_eq[ch_ref_eq][energy], c=\"k\", ls=\":\", lw=1, label=\"ref. ch. (%s) MPV\" % ch_ref_eq)\n",
    "fig.legend(framealpha=1, loc=\"upper right\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-update",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-bonus",
   "metadata": {},
   "source": [
    "## **calibration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-jesus",
   "metadata": {},
   "source": [
    "### **general settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "informal-samoa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# range for ADC value plots ((min, max)) & nr. of ADC per bin (calibration)\n",
    "adc_range_calib = (-100, 2000)\n",
    "d_adc_calib = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-observer",
   "metadata": {},
   "source": [
    "### **dataset** (```df_calib```) **creation & cleansing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sixth-adolescent",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# data cleaning...\n",
    "df_calib = pd.DataFrame()\n",
    "for energy in runs_calib:\n",
    "    b_runs_calib_temp = df.iRun==runs_calib[energy]\n",
    "    b_fid_calib_temp = (df.xCal0>fid_calib[energy][0][0]) & (df.xCal0<fid_calib[energy][0][1]) & (df.xCal0>fid_calib[energy][1][0]) & (df.xCal0<fid_calib[energy][1][1])\n",
    "    \n",
    "    df_calib = df_calib.append(df[b_1hit&b_xgood&b_angle_calib[energy]&b_runs_calib_temp&b_fid_calib_temp], sort=False)\n",
    "\n",
    "# ... and new variables\n",
    "b_time_tot = False\n",
    "for ch in ind_calo:\n",
    "    b_time_temp = (df_calib[var_time+ch]>cut_time[ch][0]) & (df_calib[var_time+ch]<cut_time[ch][1])\n",
    "    b_time_tot = b_time_tot | b_time_temp\n",
    "    \n",
    "for ich, ch in enumerate(ind_calo):\n",
    "    df_calib[var_ph+ch+\"_eq\"] = eq_par[ch]*df_calib[var_ph+ch]\n",
    "    if ich==0:\n",
    "        df_calib.loc[b_time_tot, \"ph_tot\"] = df_calib[var_ph+ch+\"_eq\"]\n",
    "    else:\n",
    "        df_calib.loc[b_time_tot, \"ph_tot\"] = df_calib[\"ph_tot\"] + df_calib[var_ph+ch+\"_eq\"]\n",
    "        \n",
    "# also, creating bin array  \n",
    "bins_calib = np.arange(adc_range_calib[0], adc_range_calib[1], d_adc_calib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-reach",
   "metadata": {},
   "source": [
    "### **equalised spectra check with calibration data**\n",
    "**(subject to boolean, settings below)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "conscious-share",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "b_plot = False  # plot this?\n",
    "energy_plot = 18.071282  # choose energy\n",
    "# # # # # # # # # #\n",
    "\n",
    "if b_plot:\n",
    "    plt.close(\"ph_calo_centre_check_calib\")\n",
    "    plt.figure(\"ph_calo_centre_check_calib\", figsize=(8, 3))\n",
    "\n",
    "    for ich, ch in enumerate(ind_calo):\n",
    "        b_run_temp = df_calib.iRun==runs_calib[energy_plot]\n",
    "        b_time = (df_calib[var_time+ch]>cut_time[ch][0]) & (df_calib[var_time+ch]<cut_time[ch][1])\n",
    "        hist = np.histogram(df_calib[b_run_temp&b_time][var_ph+ch+\"_eq\"], bins=bins_calib, density=True)\n",
    "        y_max = max(hist[0])\n",
    "        plt.plot([hist[1][i]+0.5*(hist[1][i+1]-hist[1][i]) for i in range(len(hist[1])-1)], np.array(hist[0]), label=\"ch. %s\" % ch);\n",
    "        plt.xlabel(\"PH [ADC]\")\n",
    "        plt.ylabel(\"entries [a.u.]\")\n",
    "            \n",
    "    plt.legend(framealpha=1, loc=\"upper right\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-yesterday",
   "metadata": {},
   "source": [
    "### **total PH spectra at different energies**\n",
    "**(some settings below)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "guided-tokyo",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6abb4f2ecee48dca04367f93c147b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@  20 GeV, PH MPV (width) = 157.772363 (7.134611)\n",
      "@  40 GeV, PH MPV (width) = 314.300137 (15.684809)\n",
      "@  60 GeV, PH MPV (width) = 471.663599 (29.910735)\n",
      "@  80 GeV, PH MPV (width) = 652.614700 (42.450926)\n",
      "@ 100 GeV, PH MPV (width) = 769.034417 (39.276282)\n",
      "@ 120 GeV, PH MPV (width) = 907.699944 (36.760737)\n"
     ]
    }
   ],
   "source": [
    "frac_height_fit = (0.05, 0.20)  # fraction of spectrum maximum height above which to start [0] and stop [1] the fit\n",
    "# # # # # # # # # #\n",
    "\n",
    "plt.close(\"ph_tot_all\")\n",
    "fig, ax = plt.subplots(num=\"ph_tot_all\", nrows=3, ncols=1, figsize=(6, 6), sharex=True)\n",
    "\n",
    "ymax = []\n",
    "mpv_calib = {}\n",
    "wdt_calib = {}\n",
    "\n",
    "for ienergy, energy in enumerate(runs_calib):\n",
    "    b_run_temp = df_calib.iRun == runs_calib[energy]\n",
    "    \n",
    "    hist = ax[0].hist(df_calib[b_run_temp].ph_tot, bins=bins_calib, color=\"C%d\" % ienergy, density=True, alpha=0.5, label=\"%d GeV\" % energy)\n",
    "    ymax.append(np.max(hist[0]))\n",
    "    ifwhm0 = np.argmax(hist[0]>=0.5*ymax[ienergy])\n",
    "    fwhm0 = hist[1][ifwhm0]\n",
    "    imax = np.argmax(hist[0]==ymax[ienergy])\n",
    "    ifwhm1 = imax + np.argmax(hist[0][imax:]<=0.5*ymax[ienergy])\n",
    "    fwhm1 = hist[1][ifwhm1]\n",
    "    par0 = (ymax[ienergy], hist[1][np.argmax(hist[0]==ymax[ienergy])], np.max((fwhm1-fwhm0, abs(hist[1][1]-hist[1][0]))))\n",
    "    ifitmin = np.argmax(hist[0]>=frac_height_fit[0]*ymax[ienergy])\n",
    "    ifitmax = imax + np.argmax(hist[0][imax:]<=frac_height_fit[1]*ymax[ienergy])\n",
    "    x_fit = [hist[1][i]+0.5*(hist[1][i+1]-hist[1][i]) for i in range(len(hist[1])-1)][ifitmin:ifitmax]\n",
    "    y_fit = hist[0][ifitmin:ifitmax]\n",
    "    par, _ = curve_fit(sl.fLandau, x_fit, y_fit, p0=par0)\n",
    "    x_plot_fit = np.linspace(np.min(x_fit), np.max(x_fit), 500)\n",
    "    ax[0].plot(x_plot_fit, sl.fLandau(x_plot_fit, *par))\n",
    "    ax[0].set_title(\"linear\")\n",
    "\n",
    "    ax[1].hist(df_calib[b_run_temp].ph_tot, bins=bins_calib, color=\"C%d\" % ienergy, density=True, alpha=0.5);\n",
    "    ax[1].set_yscale(\"log\")\n",
    "    ax[1].set_title(\"log\")\n",
    "    ax[1].set_ylabel(\"entries [a.u.]\")\n",
    "\n",
    "    ax[2].fill([hist[1][i]+0.5*(hist[1][i+1]-hist[1][i]) for i in range(len(hist[1])-1)], hist[0]*(1/ymax[ienergy]), alpha=0.5)\n",
    "    ax[2].plot(x_plot_fit, sl.fLandau(x_plot_fit, *par)*(1/ymax[ienergy]))\n",
    "    ax[2].set_title(\"linear, equalised maxima\")\n",
    "    ax[2].set_xlabel(\"PH [ADC]\")\n",
    "    \n",
    "    mpv_calib.update({energy: par[1]})\n",
    "    wdt_calib.update({energy: par[2]})\n",
    "    print(\"@ %3d GeV, PH MPV (width) = %f (%f)\" % (energy, mpv_calib[energy], wdt_calib[energy]))\n",
    "    \n",
    "fig.legend(framealpha=1, loc=\"upper right\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-welsh",
   "metadata": {},
   "source": [
    "### **calibration & energy resolution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "artificial-temperature",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4370f728110e4765b724c23cb37d9a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEARITY plot fitted w/ 1-degree polynomial:\n",
      "GeV =\n",
      " \n",
      "0.1318 ADC - 1.874\n"
     ]
    }
   ],
   "source": [
    "b_lin_polyfit = True  # if True (False), (non-)polynomial function is used to fit linearity plot\n",
    "lin_fit_deg = 1  # if b_lin_polyfit==True set polynomial degree, useless otherwise\n",
    "# # # # # # # # # #\n",
    "\n",
    "plt.close(\"calibration\")\n",
    "fig, ax = plt.subplots(num=\"calibration\", nrows=1, ncols=2, figsize=(8, 3.5))\n",
    "\n",
    "# linearity\n",
    "x, y = list(mpv_calib.values()), list(mpv_calib.keys())\n",
    "ax[0].plot(x, y, lw=0, marker=\"o\", ms=4)\n",
    "ax[0].plot([0], [0], lw=0, marker=\"+\", ms=10)\n",
    "\n",
    "if b_lin_polyfit:\n",
    "    par = np.polyfit(x, y, lin_fit_deg)\n",
    "    poly = np.poly1d(par, variable=\"ADC\")\n",
    "    x_plot_fit = np.linspace(np.min(x), np.max(x), 100)\n",
    "    ax[0].plot(x_plot_fit, poly(x_plot_fit), label = \"%d-degree poly.\" % lin_fit_deg, lw=1, c=\"r\")\n",
    "    ax[0].plot(np.linspace(0, np.min(x), 100), poly(np.linspace(0, np.min(x), 100)), lw=1, c=\"r\", ls=\":\")\n",
    "    print(\"LINEARITY plot fitted w/ %d-degree polynomial:\" % lin_fit_deg)\n",
    "    print(\"GeV =\")\n",
    "    print(poly)\n",
    "    \n",
    "#else:  # CASE W/ NON-POLYNOMIAL FITTING FUNCTION YET TO BE CONSIDERED\n",
    "\n",
    "ax[0].legend(loc=\"upper left\", framealpha=1)\n",
    "ax[0].set_xlabel(\"PH [ADC]\")\n",
    "ax[0].set_ylabel(\"ref. energy [GeV]\")\n",
    "\n",
    "# energy resolution\n",
    "x, y = mpv_calib.keys(), np.array([wdt/mpv for wdt, mpv in zip(wdt_calib.values(), mpv_calib.values())]) * 100  # converted into %\n",
    "ax[1].plot(x, y, lw=0, marker=\"o\", ms=4)\n",
    "ax[1].set_xlabel(\"ref. energy [GeV]\")\n",
    "ax[1].set_ylabel(\"energy resolution [%]\")\n",
    "\n",
    "# RESOLUTION FIT YET TO BE IMPLEMENTED\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-pocket",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-hungary",
   "metadata": {},
   "source": [
    "## **whiteboard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-monroe",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-reputation",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-cameroon",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
